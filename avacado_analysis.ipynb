{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dav=pd.read_csv(\"avocado.csv\",index_col=0,parse_dates=['Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>AveragePrice</th>\n",
       "      <th>Total Volume</th>\n",
       "      <th>4046</th>\n",
       "      <th>4225</th>\n",
       "      <th>4770</th>\n",
       "      <th>Total Bags</th>\n",
       "      <th>Small Bags</th>\n",
       "      <th>Large Bags</th>\n",
       "      <th>XLarge Bags</th>\n",
       "      <th>type</th>\n",
       "      <th>year</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-12-27</td>\n",
       "      <td>1.33</td>\n",
       "      <td>64236.62</td>\n",
       "      <td>1036.74</td>\n",
       "      <td>54454.85</td>\n",
       "      <td>48.16</td>\n",
       "      <td>8696.87</td>\n",
       "      <td>8603.62</td>\n",
       "      <td>93.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-12-20</td>\n",
       "      <td>1.35</td>\n",
       "      <td>54876.98</td>\n",
       "      <td>674.28</td>\n",
       "      <td>44638.81</td>\n",
       "      <td>58.33</td>\n",
       "      <td>9505.56</td>\n",
       "      <td>9408.07</td>\n",
       "      <td>97.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-12-13</td>\n",
       "      <td>0.93</td>\n",
       "      <td>118220.22</td>\n",
       "      <td>794.70</td>\n",
       "      <td>109149.67</td>\n",
       "      <td>130.50</td>\n",
       "      <td>8145.35</td>\n",
       "      <td>8042.21</td>\n",
       "      <td>103.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-12-06</td>\n",
       "      <td>1.08</td>\n",
       "      <td>78992.15</td>\n",
       "      <td>1132.00</td>\n",
       "      <td>71976.41</td>\n",
       "      <td>72.58</td>\n",
       "      <td>5811.16</td>\n",
       "      <td>5677.40</td>\n",
       "      <td>133.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-11-29</td>\n",
       "      <td>1.28</td>\n",
       "      <td>51039.60</td>\n",
       "      <td>941.48</td>\n",
       "      <td>43838.39</td>\n",
       "      <td>75.78</td>\n",
       "      <td>6183.95</td>\n",
       "      <td>5986.26</td>\n",
       "      <td>197.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>conventional</td>\n",
       "      <td>2015</td>\n",
       "      <td>Albany</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  AveragePrice  Total Volume     4046       4225    4770  \\\n",
       "0 2015-12-27          1.33      64236.62  1036.74   54454.85   48.16   \n",
       "1 2015-12-20          1.35      54876.98   674.28   44638.81   58.33   \n",
       "2 2015-12-13          0.93     118220.22   794.70  109149.67  130.50   \n",
       "3 2015-12-06          1.08      78992.15  1132.00   71976.41   72.58   \n",
       "4 2015-11-29          1.28      51039.60   941.48   43838.39   75.78   \n",
       "\n",
       "   Total Bags  Small Bags  Large Bags  XLarge Bags          type  year  region  \n",
       "0     8696.87     8603.62       93.25          0.0  conventional  2015  Albany  \n",
       "1     9505.56     9408.07       97.49          0.0  conventional  2015  Albany  \n",
       "2     8145.35     8042.21      103.14          0.0  conventional  2015  Albany  \n",
       "3     5811.16     5677.40      133.76          0.0  conventional  2015  Albany  \n",
       "4     6183.95     5986.26      197.69          0.0  conventional  2015  Albany  "
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dav.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date            0\n",
       "AveragePrice    0\n",
       "Total Volume    0\n",
       "4046            0\n",
       "4225            0\n",
       "4770            0\n",
       "Total Bags      0\n",
       "Small Bags      0\n",
       "Large Bags      0\n",
       "XLarge Bags     0\n",
       "type            0\n",
       "year            0\n",
       "region          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking null values\n",
    "dav.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date            datetime64[ns]\n",
       "AveragePrice           float64\n",
       "Total Volume           float64\n",
       "4046                   float64\n",
       "4225                   float64\n",
       "4770                   float64\n",
       "Total Bags             float64\n",
       "Small Bags             float64\n",
       "Large Bags             float64\n",
       "XLarge Bags            float64\n",
       "type                    object\n",
       "year                     int64\n",
       "region                  object\n",
       "dtype: object"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking datatypes\n",
    "dav.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "conventional    9126\n",
       "organic         9123\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#checking how many types of avacados are present\n",
    "dav['type'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1cf882a2288>"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#First lets perform linear regression on the prices\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,8))\n",
    "sns.barplot(x=\"year\",y=\"AveragePrice\",hue=\"type\",data=dav)\n",
    "#In 2017 for coneventional and organic average price is high compared to other years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#As datatype is object we are using Label Encoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "le=LabelEncoder()\n",
    "for col in dav.columns:\n",
    "    if dav[col].dtype==object:\n",
    "        dav[col]=le.fit_transform(dav[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1cf904e6d08>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(dav.corr())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "dav.drop(\"Date\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lets remove the outliers\n",
    "from scipy.stats import zscore\n",
    "import numpy as np\n",
    "z=np.abs(zscore(dav))\n",
    "dav_new=dav[(z<3).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17651, 12)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dav_new.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(18249, 12)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dav.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AveragePrice    0.377432\n",
       "Total Volume    3.767138\n",
       "4046            4.909848\n",
       "4225            4.455745\n",
       "4770            5.117170\n",
       "Total Bags      4.066771\n",
       "Small Bags      4.222706\n",
       "Large Bags      5.053434\n",
       "XLarge Bags     6.135607\n",
       "type           -0.037741\n",
       "year            0.229976\n",
       "region          0.012798\n",
       "dtype: float64"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dav_new.skew()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AveragePrice</th>\n",
       "      <th>Total Volume</th>\n",
       "      <th>4046</th>\n",
       "      <th>4225</th>\n",
       "      <th>4770</th>\n",
       "      <th>Total Bags</th>\n",
       "      <th>Small Bags</th>\n",
       "      <th>Large Bags</th>\n",
       "      <th>XLarge Bags</th>\n",
       "      <th>type</th>\n",
       "      <th>year</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.33</td>\n",
       "      <td>64236.62</td>\n",
       "      <td>1036.74</td>\n",
       "      <td>54454.85</td>\n",
       "      <td>48.16</td>\n",
       "      <td>8696.87</td>\n",
       "      <td>8603.62</td>\n",
       "      <td>93.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.35</td>\n",
       "      <td>54876.98</td>\n",
       "      <td>674.28</td>\n",
       "      <td>44638.81</td>\n",
       "      <td>58.33</td>\n",
       "      <td>9505.56</td>\n",
       "      <td>9408.07</td>\n",
       "      <td>97.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.93</td>\n",
       "      <td>118220.22</td>\n",
       "      <td>794.70</td>\n",
       "      <td>109149.67</td>\n",
       "      <td>130.50</td>\n",
       "      <td>8145.35</td>\n",
       "      <td>8042.21</td>\n",
       "      <td>103.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.08</td>\n",
       "      <td>78992.15</td>\n",
       "      <td>1132.00</td>\n",
       "      <td>71976.41</td>\n",
       "      <td>72.58</td>\n",
       "      <td>5811.16</td>\n",
       "      <td>5677.40</td>\n",
       "      <td>133.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.28</td>\n",
       "      <td>51039.60</td>\n",
       "      <td>941.48</td>\n",
       "      <td>43838.39</td>\n",
       "      <td>75.78</td>\n",
       "      <td>6183.95</td>\n",
       "      <td>5986.26</td>\n",
       "      <td>197.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AveragePrice  Total Volume     4046       4225    4770  Total Bags  \\\n",
       "0          1.33      64236.62  1036.74   54454.85   48.16     8696.87   \n",
       "1          1.35      54876.98   674.28   44638.81   58.33     9505.56   \n",
       "2          0.93     118220.22   794.70  109149.67  130.50     8145.35   \n",
       "3          1.08      78992.15  1132.00   71976.41   72.58     5811.16   \n",
       "4          1.28      51039.60   941.48   43838.39   75.78     6183.95   \n",
       "\n",
       "   Small Bags  Large Bags  XLarge Bags  type  year  region  \n",
       "0     8603.62       93.25          0.0     0  2015       0  \n",
       "1     9408.07       97.49          0.0     0  2015       0  \n",
       "2     8042.21      103.14          0.0     0  2015       0  \n",
       "3     5677.40      133.76          0.0     0  2015       0  \n",
       "4     5986.26      197.69          0.0     0  2015       0  "
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dav_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=dav_new.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total Volume</th>\n",
       "      <th>4046</th>\n",
       "      <th>4225</th>\n",
       "      <th>4770</th>\n",
       "      <th>Total Bags</th>\n",
       "      <th>Small Bags</th>\n",
       "      <th>Large Bags</th>\n",
       "      <th>XLarge Bags</th>\n",
       "      <th>type</th>\n",
       "      <th>year</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>64236.62</td>\n",
       "      <td>1036.74</td>\n",
       "      <td>54454.85</td>\n",
       "      <td>48.16</td>\n",
       "      <td>8696.87</td>\n",
       "      <td>8603.62</td>\n",
       "      <td>93.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>54876.98</td>\n",
       "      <td>674.28</td>\n",
       "      <td>44638.81</td>\n",
       "      <td>58.33</td>\n",
       "      <td>9505.56</td>\n",
       "      <td>9408.07</td>\n",
       "      <td>97.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>118220.22</td>\n",
       "      <td>794.70</td>\n",
       "      <td>109149.67</td>\n",
       "      <td>130.50</td>\n",
       "      <td>8145.35</td>\n",
       "      <td>8042.21</td>\n",
       "      <td>103.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>78992.15</td>\n",
       "      <td>1132.00</td>\n",
       "      <td>71976.41</td>\n",
       "      <td>72.58</td>\n",
       "      <td>5811.16</td>\n",
       "      <td>5677.40</td>\n",
       "      <td>133.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>51039.60</td>\n",
       "      <td>941.48</td>\n",
       "      <td>43838.39</td>\n",
       "      <td>75.78</td>\n",
       "      <td>6183.95</td>\n",
       "      <td>5986.26</td>\n",
       "      <td>197.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>17074.83</td>\n",
       "      <td>2046.96</td>\n",
       "      <td>1529.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13498.67</td>\n",
       "      <td>13066.82</td>\n",
       "      <td>431.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>13888.04</td>\n",
       "      <td>1191.70</td>\n",
       "      <td>3431.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9264.84</td>\n",
       "      <td>8940.04</td>\n",
       "      <td>324.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>13766.76</td>\n",
       "      <td>1191.92</td>\n",
       "      <td>2452.79</td>\n",
       "      <td>727.94</td>\n",
       "      <td>9394.11</td>\n",
       "      <td>9351.80</td>\n",
       "      <td>42.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>16205.22</td>\n",
       "      <td>1527.63</td>\n",
       "      <td>2981.04</td>\n",
       "      <td>727.01</td>\n",
       "      <td>10969.54</td>\n",
       "      <td>10919.54</td>\n",
       "      <td>50.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>17489.58</td>\n",
       "      <td>2894.77</td>\n",
       "      <td>2356.13</td>\n",
       "      <td>224.53</td>\n",
       "      <td>12014.15</td>\n",
       "      <td>11988.14</td>\n",
       "      <td>26.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17651 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Total Volume     4046       4225    4770  Total Bags  Small Bags  \\\n",
       "0       64236.62  1036.74   54454.85   48.16     8696.87     8603.62   \n",
       "1       54876.98   674.28   44638.81   58.33     9505.56     9408.07   \n",
       "2      118220.22   794.70  109149.67  130.50     8145.35     8042.21   \n",
       "3       78992.15  1132.00   71976.41   72.58     5811.16     5677.40   \n",
       "4       51039.60   941.48   43838.39   75.78     6183.95     5986.26   \n",
       "..           ...      ...        ...     ...         ...         ...   \n",
       "7       17074.83  2046.96    1529.20    0.00    13498.67    13066.82   \n",
       "8       13888.04  1191.70    3431.50    0.00     9264.84     8940.04   \n",
       "9       13766.76  1191.92    2452.79  727.94     9394.11     9351.80   \n",
       "10      16205.22  1527.63    2981.04  727.01    10969.54    10919.54   \n",
       "11      17489.58  2894.77    2356.13  224.53    12014.15    11988.14   \n",
       "\n",
       "    Large Bags  XLarge Bags  type  year  region  \n",
       "0        93.25          0.0     0  2015       0  \n",
       "1        97.49          0.0     0  2015       0  \n",
       "2       103.14          0.0     0  2015       0  \n",
       "3       133.76          0.0     0  2015       0  \n",
       "4       197.69          0.0     0  2015       0  \n",
       "..         ...          ...   ...   ...     ...  \n",
       "7       431.85          0.0     1  2018      53  \n",
       "8       324.80          0.0     1  2018      53  \n",
       "9        42.31          0.0     1  2018      53  \n",
       "10       50.00          0.0     1  2018      53  \n",
       "11       26.01          0.0     1  2018      53  \n",
       "\n",
       "[17651 rows x 11 columns]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.3920086 , -0.34945151, -0.27849691, ..., -1.01904715,\n",
       "        -1.21001338, -1.69549505],\n",
       "       [-0.40125088, -0.3502761 , -0.30309279, ..., -1.01904715,\n",
       "        -1.21001338, -1.69549505],\n",
       "       [-0.33870193, -0.35000214, -0.14144901, ..., -1.01904715,\n",
       "        -1.21001338, -1.69549505],\n",
       "       ...,\n",
       "       [-0.44184559, -0.34909848, -0.40879759, ...,  0.98130886,\n",
       "         1.98075592,  1.74705401],\n",
       "       [-0.43943771, -0.34833475, -0.40747397, ...,  0.98130886,\n",
       "         1.98075592,  1.74705401],\n",
       "       [-0.43816945, -0.34522454, -0.40903979, ...,  0.98130886,\n",
       "         1.98075592,  1.74705401]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "sc=StandardScaler()\n",
    "x=sc.fit_transform(x)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=dav_new.iloc[:,0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AveragePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17651 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    AveragePrice\n",
       "0           1.33\n",
       "1           1.35\n",
       "2           0.93\n",
       "3           1.08\n",
       "4           1.28\n",
       "..           ...\n",
       "7           1.63\n",
       "8           1.71\n",
       "9           1.87\n",
       "10          1.93\n",
       "11          1.62\n",
       "\n",
       "[17651 rows x 1 columns]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r2 score correspoinding to r_state 42 is 0.40897922381452334\n",
      "r2 score correspoinding to r_state 43 is 0.4297468870200334\n",
      "r2 score correspoinding to r_state 44 is 0.3863768120838831\n",
      "r2 score correspoinding to r_state 45 is 0.4079255846404083\n",
      "r2 score correspoinding to r_state 46 is 0.42322823520748276\n",
      "r2 score correspoinding to r_state 47 is 0.41539257149124\n",
      "r2 score correspoinding to r_state 48 is 0.41485807758227566\n",
      "r2 score correspoinding to r_state 49 is 0.4186249720283135\n",
      "r2 score correspoinding to r_state 50 is 0.4040407369679222\n",
      "r2 score correspoinding to r_state 51 is 0.4041767573670161\n",
      "r2 score correspoinding to r_state 52 is 0.40932788677316023\n",
      "r2 score correspoinding to r_state 53 is 0.4256230764261032\n",
      "r2 score correspoinding to r_state 54 is 0.3911432294413377\n",
      "r2 score correspoinding to r_state 55 is 0.41552950092075924\n",
      "r2 score correspoinding to r_state 56 is 0.42129082021844433\n",
      "r2 score correspoinding to r_state 57 is 0.42053365547032595\n",
      "r2 score correspoinding to r_state 58 is 0.42655315041201525\n",
      "r2 score correspoinding to r_state 59 is 0.3990268372258159\n",
      "r2 score correspoinding to r_state 60 is 0.42391561093702856\n",
      "r2 score correspoinding to r_state 61 is 0.39241422480090826\n",
      "r2 score correspoinding to r_state 62 is 0.38710023170659824\n",
      "r2 score correspoinding to r_state 63 is 0.4120862535029344\n",
      "r2 score correspoinding to r_state 64 is 0.4201584469920132\n",
      "r2 score correspoinding to r_state 65 is 0.40413554583428557\n",
      "r2 score correspoinding to r_state 66 is 0.3934905208957089\n",
      "r2 score correspoinding to r_state 67 is 0.4095159538587504\n",
      "r2 score correspoinding to r_state 68 is 0.40552544794366463\n",
      "r2 score correspoinding to r_state 69 is 0.42011482559883007\n",
      "r2 score correspoinding to r_state 70 is 0.4136150078923758\n",
      "r2 score correspoinding to r_state 71 is 0.41088552072812123\n",
      "r2 score correspoinding to r_state 72 is 0.41455256044482236\n",
      "r2 score correspoinding to r_state 73 is 0.3945204345161921\n",
      "r2 score correspoinding to r_state 74 is 0.40984772859296004\n",
      "r2 score correspoinding to r_state 75 is 0.4084578570099261\n",
      "r2 score correspoinding to r_state 76 is 0.4197239125082891\n",
      "r2 score correspoinding to r_state 77 is 0.4087639276899123\n",
      "r2 score correspoinding to r_state 78 is 0.4106363769823269\n",
      "r2 score correspoinding to r_state 79 is 0.4173382661108078\n",
      "r2 score correspoinding to r_state 80 is 0.40846069626663006\n",
      "r2 score correspoinding to r_state 81 is 0.4132750029808776\n",
      "r2 score correspoinding to r_state 82 is 0.4314227103825182\n",
      "r2 score correspoinding to r_state 83 is 0.3942331501765892\n",
      "r2 score correspoinding to r_state 84 is 0.43344083019418256\n",
      "r2 score correspoinding to r_state 85 is 0.42625001592000755\n",
      "r2 score correspoinding to r_state 86 is 0.4172455787892605\n",
      "r2 score correspoinding to r_state 87 is 0.4058685059705055\n",
      "r2 score correspoinding to r_state 88 is 0.4082752767813892\n",
      "r2 score correspoinding to r_state 89 is 0.4204883748953332\n",
      "r2 score correspoinding to r_state 90 is 0.3971616880451452\n",
      "r2 score correspoinding to r_state 91 is 0.40748870195798736\n",
      "r2 score correspoinding to r_state 92 is 0.4008607408823873\n",
      "r2 score correspoinding to r_state 93 is 0.4127221819783784\n",
      "r2 score correspoinding to r_state 94 is 0.403797139170344\n",
      "r2 score correspoinding to r_state 95 is 0.41808555271034054\n",
      "r2 score correspoinding to r_state 96 is 0.41778694928815696\n",
      "r2 score correspoinding to r_state 97 is 0.38548394383866236\n",
      "r2 score correspoinding to r_state 98 is 0.4197225743933414\n",
      "r2 score correspoinding to r_state 99 is 0.4239998887052919\n",
      "r2 score correspoinding to r_state 100 is 0.416361358754921\n",
      "84\n",
      "0.43344083019418256\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error,mean_squared_error,r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "max_r_score=0\n",
    "for r_state in range(42,101):\n",
    "    x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=r_state,test_size=0.2)\n",
    "    lr=LinearRegression()\n",
    "    lr.fit(x_train,y_train)\n",
    "    y_pred=lr.predict(x_test)\n",
    "    r2_scr=r2_score(y_test,y_pred)\n",
    "    print(\"r2 score correspoinding to r_state\",r_state ,\"is\",r2_scr)\n",
    "    if r2_scr>max_r_score:\n",
    "        max_r_score=r2_scr\n",
    "        final_r_state=r_state\n",
    "        \n",
    "print(final_r_state)\n",
    "print(max_r_score)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.63228713e-01  4.74525190e-02  3.02981452e-01 -4.74467414e-02\n",
      " -1.37462994e+02]\n",
      "-27.46464706347199 54.9993880449692\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "lrscores=cross_val_score(lr,x,y,scoring=\"r2\",cv=5)\n",
    "print(lrscores)\n",
    "print(lrscores.mean(),lrscores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=None, error_score=nan,\n",
      "             estimator=Lasso(alpha=1.0, copy_X=True, fit_intercept=True,\n",
      "                             max_iter=1000, normalize=False, positive=False,\n",
      "                             precompute=False, random_state=None,\n",
      "                             selection='cyclic', tol=0.0001, warm_start=False),\n",
      "             iid='deprecated', n_jobs=None,\n",
      "             param_grid={'alpha': [1, 0.1, 0.01, 0.0001, 0.001, 0]},\n",
      "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
      "             scoring=None, verbose=0)\n",
      "0.4104587223925977\n",
      "0.0001\n",
      "{'alpha': 0.0001}\n",
      "[-3.85189856 -0.63909317 -0.04763459 -0.44449249 -0.80022956]\n",
      "-1.156669674837169 1.3708646092588772\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "alphavalue={'alpha':[1,0.1,0.01,0.0001,0.001,0]}\n",
    "model=Lasso()\n",
    "grid=GridSearchCV(estimator=model,param_grid=alphavalue)\n",
    "grid.fit(x_train,y_train)\n",
    "print(grid)\n",
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_.alpha)\n",
    "print(grid.best_params_)\n",
    "from sklearn.model_selection import cross_val_score\n",
    "lasscores=cross_val_score(model,x,y,scoring=\"r2\",cv=5)\n",
    "print(lasscores)\n",
    "print(lasscores.mean(),lasscores.std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv=None, error_score=nan,\n",
      "             estimator=Ridge(alpha=1.0, copy_X=True, fit_intercept=True,\n",
      "                             max_iter=None, normalize=False, random_state=None,\n",
      "                             solver='auto', tol=0.001),\n",
      "             iid='deprecated', n_jobs=None,\n",
      "             param_grid={'alpha': [1, 0.1, 0.01, 0.0001, 0.001, 0]},\n",
      "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
      "             scoring=None, verbose=0)\n",
      "0.4104586698721978\n",
      "1\n",
      "{'alpha': 1}\n",
      "[-0.1600173   0.04767375  0.30313248 -0.04687479 -0.00533706]\n",
      "0.027715417842974467 0.1537222355385653\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "alphavalue={'alpha':[1,0.1,0.01,0.0001,0.001,0]}\n",
    "model=Ridge()\n",
    "grid=GridSearchCV(estimator=model,param_grid=alphavalue)\n",
    "grid.fit(x_train,y_train)\n",
    "print(grid)\n",
    "print(grid.best_score_)\n",
    "print(grid.best_estimator_.alpha)\n",
    "print(grid.best_params_)\n",
    "from sklearn.model_selection import cross_val_score\n",
    "lasscores=cross_val_score(model,x,y,scoring=\"r2\",cv=5)\n",
    "print(lasscores)\n",
    "print(lasscores.mean(),lasscores.std())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8503241811134762\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rfr=RandomForestRegressor(n_estimators=100,random_state=45)\n",
    "rfr.fit(x_train,y_train)\n",
    "predrf=rfr.predict(x_test)\n",
    "print(r2_score(y_test,predrf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.20067317 0.29065931 0.56428012 0.31065378 0.0296989 ]\n",
      "0.27919305689822443 0.17367129497534708\n"
     ]
    }
   ],
   "source": [
    "rfrcores=cross_val_score(rfr,x,y,scoring=\"r2\",cv=5)\n",
    "print(rfrcores)\n",
    "print(rfrcores.mean(),rfrcores.std())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5034249871361653\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "adr=AdaBoostRegressor(n_estimators=50)\n",
    "adr.fit(x_train,y_train)\n",
    "predad=adr.predict(x_test)\n",
    "print(r2_score(y_test,predad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rfr.avacado.pkl']"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#as per the analysis randomforestRegressor having high r2score\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(rfr,'rfr.avacado.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AveragePrice</th>\n",
       "      <th>Total Volume</th>\n",
       "      <th>4046</th>\n",
       "      <th>4225</th>\n",
       "      <th>4770</th>\n",
       "      <th>Total Bags</th>\n",
       "      <th>Small Bags</th>\n",
       "      <th>Large Bags</th>\n",
       "      <th>XLarge Bags</th>\n",
       "      <th>type</th>\n",
       "      <th>year</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.33</td>\n",
       "      <td>64236.62</td>\n",
       "      <td>1036.74</td>\n",
       "      <td>54454.85</td>\n",
       "      <td>48.16</td>\n",
       "      <td>8696.87</td>\n",
       "      <td>8603.62</td>\n",
       "      <td>93.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.35</td>\n",
       "      <td>54876.98</td>\n",
       "      <td>674.28</td>\n",
       "      <td>44638.81</td>\n",
       "      <td>58.33</td>\n",
       "      <td>9505.56</td>\n",
       "      <td>9408.07</td>\n",
       "      <td>97.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.93</td>\n",
       "      <td>118220.22</td>\n",
       "      <td>794.70</td>\n",
       "      <td>109149.67</td>\n",
       "      <td>130.50</td>\n",
       "      <td>8145.35</td>\n",
       "      <td>8042.21</td>\n",
       "      <td>103.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.08</td>\n",
       "      <td>78992.15</td>\n",
       "      <td>1132.00</td>\n",
       "      <td>71976.41</td>\n",
       "      <td>72.58</td>\n",
       "      <td>5811.16</td>\n",
       "      <td>5677.40</td>\n",
       "      <td>133.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.28</td>\n",
       "      <td>51039.60</td>\n",
       "      <td>941.48</td>\n",
       "      <td>43838.39</td>\n",
       "      <td>75.78</td>\n",
       "      <td>6183.95</td>\n",
       "      <td>5986.26</td>\n",
       "      <td>197.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   AveragePrice  Total Volume     4046       4225    4770  Total Bags  \\\n",
       "0          1.33      64236.62  1036.74   54454.85   48.16     8696.87   \n",
       "1          1.35      54876.98   674.28   44638.81   58.33     9505.56   \n",
       "2          0.93     118220.22   794.70  109149.67  130.50     8145.35   \n",
       "3          1.08      78992.15  1132.00   71976.41   72.58     5811.16   \n",
       "4          1.28      51039.60   941.48   43838.39   75.78     6183.95   \n",
       "\n",
       "   Small Bags  Large Bags  XLarge Bags  type  year  region  \n",
       "0     8603.62       93.25          0.0     0  2015       0  \n",
       "1     9408.07       97.49          0.0     0  2015       0  \n",
       "2     8042.21      103.14          0.0     0  2015       0  \n",
       "3     5677.40      133.76          0.0     0  2015       0  \n",
       "4     5986.26      197.69          0.0     0  2015       0  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dav_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_new=pd.DataFrame()\n",
    "y_new['type']=dav_new['type']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   type\n",
       "0     0\n",
       "1     0\n",
       "2     0\n",
       "3     0\n",
       "4     0"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "dav_new.drop(\"type\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_new=dav_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AveragePrice</th>\n",
       "      <th>Total Volume</th>\n",
       "      <th>4046</th>\n",
       "      <th>4225</th>\n",
       "      <th>4770</th>\n",
       "      <th>Total Bags</th>\n",
       "      <th>Small Bags</th>\n",
       "      <th>Large Bags</th>\n",
       "      <th>XLarge Bags</th>\n",
       "      <th>year</th>\n",
       "      <th>region</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.33</td>\n",
       "      <td>64236.62</td>\n",
       "      <td>1036.74</td>\n",
       "      <td>54454.85</td>\n",
       "      <td>48.16</td>\n",
       "      <td>8696.87</td>\n",
       "      <td>8603.62</td>\n",
       "      <td>93.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.35</td>\n",
       "      <td>54876.98</td>\n",
       "      <td>674.28</td>\n",
       "      <td>44638.81</td>\n",
       "      <td>58.33</td>\n",
       "      <td>9505.56</td>\n",
       "      <td>9408.07</td>\n",
       "      <td>97.49</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.93</td>\n",
       "      <td>118220.22</td>\n",
       "      <td>794.70</td>\n",
       "      <td>109149.67</td>\n",
       "      <td>130.50</td>\n",
       "      <td>8145.35</td>\n",
       "      <td>8042.21</td>\n",
       "      <td>103.14</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.08</td>\n",
       "      <td>78992.15</td>\n",
       "      <td>1132.00</td>\n",
       "      <td>71976.41</td>\n",
       "      <td>72.58</td>\n",
       "      <td>5811.16</td>\n",
       "      <td>5677.40</td>\n",
       "      <td>133.76</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.28</td>\n",
       "      <td>51039.60</td>\n",
       "      <td>941.48</td>\n",
       "      <td>43838.39</td>\n",
       "      <td>75.78</td>\n",
       "      <td>6183.95</td>\n",
       "      <td>5986.26</td>\n",
       "      <td>197.69</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.63</td>\n",
       "      <td>17074.83</td>\n",
       "      <td>2046.96</td>\n",
       "      <td>1529.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13498.67</td>\n",
       "      <td>13066.82</td>\n",
       "      <td>431.85</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1.71</td>\n",
       "      <td>13888.04</td>\n",
       "      <td>1191.70</td>\n",
       "      <td>3431.50</td>\n",
       "      <td>0.00</td>\n",
       "      <td>9264.84</td>\n",
       "      <td>8940.04</td>\n",
       "      <td>324.80</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1.87</td>\n",
       "      <td>13766.76</td>\n",
       "      <td>1191.92</td>\n",
       "      <td>2452.79</td>\n",
       "      <td>727.94</td>\n",
       "      <td>9394.11</td>\n",
       "      <td>9351.80</td>\n",
       "      <td>42.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1.93</td>\n",
       "      <td>16205.22</td>\n",
       "      <td>1527.63</td>\n",
       "      <td>2981.04</td>\n",
       "      <td>727.01</td>\n",
       "      <td>10969.54</td>\n",
       "      <td>10919.54</td>\n",
       "      <td>50.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1.62</td>\n",
       "      <td>17489.58</td>\n",
       "      <td>2894.77</td>\n",
       "      <td>2356.13</td>\n",
       "      <td>224.53</td>\n",
       "      <td>12014.15</td>\n",
       "      <td>11988.14</td>\n",
       "      <td>26.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2018</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17651 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    AveragePrice  Total Volume     4046       4225    4770  Total Bags  \\\n",
       "0           1.33      64236.62  1036.74   54454.85   48.16     8696.87   \n",
       "1           1.35      54876.98   674.28   44638.81   58.33     9505.56   \n",
       "2           0.93     118220.22   794.70  109149.67  130.50     8145.35   \n",
       "3           1.08      78992.15  1132.00   71976.41   72.58     5811.16   \n",
       "4           1.28      51039.60   941.48   43838.39   75.78     6183.95   \n",
       "..           ...           ...      ...        ...     ...         ...   \n",
       "7           1.63      17074.83  2046.96    1529.20    0.00    13498.67   \n",
       "8           1.71      13888.04  1191.70    3431.50    0.00     9264.84   \n",
       "9           1.87      13766.76  1191.92    2452.79  727.94     9394.11   \n",
       "10          1.93      16205.22  1527.63    2981.04  727.01    10969.54   \n",
       "11          1.62      17489.58  2894.77    2356.13  224.53    12014.15   \n",
       "\n",
       "    Small Bags  Large Bags  XLarge Bags  year  region  \n",
       "0      8603.62       93.25          0.0  2015       0  \n",
       "1      9408.07       97.49          0.0  2015       0  \n",
       "2      8042.21      103.14          0.0  2015       0  \n",
       "3      5677.40      133.76          0.0  2015       0  \n",
       "4      5986.26      197.69          0.0  2015       0  \n",
       "..         ...         ...          ...   ...     ...  \n",
       "7     13066.82      431.85          0.0  2018      53  \n",
       "8      8940.04      324.80          0.0  2018      53  \n",
       "9      9351.80       42.31          0.0  2018      53  \n",
       "10    10919.54       50.00          0.0  2018      53  \n",
       "11    11988.14       26.01          0.0  2018      53  \n",
       "\n",
       "[17651 rows x 11 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy_score: 40 is 0.9371282922684792\n",
      "accuracy_score: 41 is 0.935429056924384\n",
      "accuracy_score: 42 is 0.9325969980175588\n",
      "accuracy_score: 43 is 0.9311809685641461\n",
      "accuracy_score: 44 is 0.9331634097989239\n",
      "accuracy_score: 45 is 0.9266496743132258\n",
      "accuracy_score: 46 is 0.9359954687057491\n",
      "accuracy_score: 47 is 0.9300481450014161\n",
      "accuracy_score: 48 is 0.9308977626734636\n",
      "accuracy_score: 49 is 0.924667233078448\n",
      "accuracy_score: 50 is 0.9331634097989239\n",
      "accuracy_score: 51 is 0.9255168507504956\n",
      "accuracy_score: 52 is 0.9258000566411781\n",
      "accuracy_score: 53 is 0.9357122628150666\n",
      "accuracy_score: 54 is 0.9249504389691305\n",
      "accuracy_score: 55 is 0.9334466156896063\n",
      "accuracy_score: 56 is 0.930614556782781\n",
      "accuracy_score: 57 is 0.9289153214386859\n",
      "accuracy_score: 58 is 0.9317473803455112\n",
      "accuracy_score: 59 is 0.9331634097989239\n",
      "accuracy_score: 60 is 0.9379779099405268\n",
      "accuracy_score: 61 is 0.9274992919852733\n",
      "accuracy_score: 62 is 0.9300481450014161\n",
      "accuracy_score: 63 is 0.9303313508920985\n",
      "accuracy_score: 64 is 0.9337298215802888\n",
      "accuracy_score: 65 is 0.9274992919852733\n",
      "accuracy_score: 66 is 0.9289153214386859\n",
      "accuracy_score: 67 is 0.9368450863777966\n",
      "accuracy_score: 68 is 0.9266496743132258\n",
      "accuracy_score: 69 is 0.9269328802039083\n",
      "accuracy_score: 70 is 0.9274992919852733\n",
      "accuracy_score: 71 is 0.9277824978759558\n",
      "accuracy_score: 72 is 0.935429056924384\n",
      "accuracy_score: 73 is 0.9308977626734636\n",
      "accuracy_score: 74 is 0.9362786745964317\n",
      "accuracy_score: 75 is 0.9274992919852733\n",
      "accuracy_score: 76 is 0.9274992919852733\n",
      "accuracy_score: 77 is 0.9331634097989239\n",
      "accuracy_score: 78 is 0.9283489096573209\n",
      "accuracy_score: 79 is 0.935429056924384\n",
      "accuracy_score: 80 is 0.9311809685641461\n",
      "accuracy_score: 81 is 0.9334466156896063\n",
      "accuracy_score: 82 is 0.9255168507504956\n",
      "accuracy_score: 83 is 0.9226847918436704\n",
      "accuracy_score: 84 is 0.9252336448598131\n",
      "accuracy_score: 85 is 0.9303313508920985\n",
      "accuracy_score: 86 is 0.9334466156896063\n",
      "accuracy_score: 87 is 0.9331634097989239\n",
      "accuracy_score: 88 is 0.9241008212970829\n",
      "accuracy_score: 89 is 0.930614556782781\n",
      "accuracy_score: 90 is 0.9300481450014161\n",
      "accuracy_score: 91 is 0.9280657037666383\n",
      "accuracy_score: 92 is 0.9272160860945907\n",
      "accuracy_score: 93 is 0.9303313508920985\n",
      "accuracy_score: 94 is 0.9379779099405268\n",
      "accuracy_score: 95 is 0.9303313508920985\n",
      "accuracy_score: 96 is 0.930614556782781\n",
      "accuracy_score: 97 is 0.924667233078448\n",
      "accuracy_score: 98 is 0.929481733220051\n",
      "accuracy_score: 99 is 0.9291985273293685\n",
      "accuracy_score: 100 is 0.9371282922684792\n",
      "60\n",
      "0.9379779099405268\n"
     ]
    }
   ],
   "source": [
    "#Performing Logistic regression checking for random state value\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "max_acc_score=0\n",
    "for r_state in range(40,101):\n",
    "    x_train1,x_test1,y_train1,y_test1=train_test_split(x_new,y_new,random_state=r_state,test_size=0.2)\n",
    "    lg=LogisticRegression()\n",
    "    lg.fit(x_train1,y_train1)\n",
    "    y_pred1=lg.predict(x_test1)\n",
    "    acc_score=accuracy_score(y_test1,y_pred1)\n",
    "    print(\"accuracy_score:\",r_state,\"is\",acc_score)\n",
    "    if acc_score>max_acc_score:\n",
    "        max_acc_score=acc_score\n",
    "        final_r_state=r_state\n",
    "        \n",
    "print(final_r_state)\n",
    "print(max_acc_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "KNN=KNeighborsClassifier(n_neighbors=6)\n",
    "svc=SVC()\n",
    "lr=LogisticRegression()\n",
    "dtc=DecisionTreeClassifier(random_state=6)\n",
    "rf=RandomForestClassifier(n_estimators=100,random_state=55)\n",
    "gnb=GaussianNB()\n",
    "models=[]\n",
    "models.append(('KNeighborsClassifier',KNN))\n",
    "models.append(('SVC',svc))\n",
    "models.append(('LogisticRegression',lr))\n",
    "models.append(('DecisionTreeClassifier',dtc))\n",
    "models.append(('GaussianNB',gnb))\n",
    "models.append(('RandomForestClassifier',rf))\n",
    "from sklearn.metrics import classification_report,confusion_matrix,accuracy_score,roc_curve,auc\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************* KNeighborsClassifier ***********************\n",
      "\n",
      "\n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "                     metric_params=None, n_jobs=None, n_neighbors=6, p=2,\n",
      "                     weights='uniform')\n",
      "\n",
      "\n",
      "accuracy_score= 0.9728122344944775\n",
      "\n",
      "\n",
      "Cross_val_score= 0.9375692575208776\n",
      "\n",
      "\n",
      "roc auc score= 0.9731282680079475\n",
      "\n",
      "\n",
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.99      0.97      1726\n",
      "           1       0.99      0.96      0.97      1805\n",
      "\n",
      "    accuracy                           0.97      3531\n",
      "   macro avg       0.97      0.97      0.97      3531\n",
      "weighted avg       0.97      0.97      0.97      3531\n",
      "\n",
      "\n",
      "\n",
      "[[1704   22]\n",
      " [  74 1731]]\n",
      "\n",
      "\n",
      "************************* SVC ***********************\n",
      "\n",
      "\n",
      "SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None, coef0=0.0,\n",
      "    decision_function_shape='ovr', degree=3, gamma='scale', kernel='rbf',\n",
      "    max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "    tol=0.001, verbose=False)\n",
      "\n",
      "\n",
      "accuracy_score= 0.9161710563579722\n",
      "\n",
      "\n",
      "Cross_val_score= 0.9089573595038803\n",
      "\n",
      "\n",
      "roc auc score= 0.9158881759500295\n",
      "\n",
      "\n",
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.90      0.91      1726\n",
      "           1       0.91      0.93      0.92      1805\n",
      "\n",
      "    accuracy                           0.92      3531\n",
      "   macro avg       0.92      0.92      0.92      3531\n",
      "weighted avg       0.92      0.92      0.92      3531\n",
      "\n",
      "\n",
      "\n",
      "[[1559  167]\n",
      " [ 129 1676]]\n",
      "\n",
      "\n",
      "************************* LogisticRegression ***********************\n",
      "\n",
      "\n",
      "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
      "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
      "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
      "                   warm_start=False)\n",
      "\n",
      "\n",
      "accuracy_score= 0.9371282922684792\n",
      "\n",
      "\n",
      "Cross_val_score= 0.9286734317402366\n",
      "\n",
      "\n",
      "roc auc score= 0.9363360755979111\n",
      "\n",
      "\n",
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.90      0.93      1726\n",
      "           1       0.91      0.97      0.94      1805\n",
      "\n",
      "    accuracy                           0.94      3531\n",
      "   macro avg       0.94      0.94      0.94      3531\n",
      "weighted avg       0.94      0.94      0.94      3531\n",
      "\n",
      "\n",
      "\n",
      "[[1555  171]\n",
      " [  51 1754]]\n",
      "\n",
      "\n",
      "************************* DecisionTreeClassifier ***********************\n",
      "\n",
      "\n",
      "DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',\n",
      "                       max_depth=None, max_features=None, max_leaf_nodes=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, presort='deprecated',\n",
      "                       random_state=6, splitter='best')\n",
      "\n",
      "\n",
      "accuracy_score= 0.989238176154064\n",
      "\n",
      "\n",
      "Cross_val_score= 0.9759781391663109\n",
      "\n",
      "\n",
      "roc auc score= 0.9891947500024073\n",
      "\n",
      "\n",
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99      1726\n",
      "           1       0.99      0.99      0.99      1805\n",
      "\n",
      "    accuracy                           0.99      3531\n",
      "   macro avg       0.99      0.99      0.99      3531\n",
      "weighted avg       0.99      0.99      0.99      3531\n",
      "\n",
      "\n",
      "\n",
      "[[1704   22]\n",
      " [  16 1789]]\n",
      "\n",
      "\n",
      "************************* GaussianNB ***********************\n",
      "\n",
      "\n",
      "GaussianNB(priors=None, var_smoothing=1e-09)\n",
      "\n",
      "\n",
      "accuracy_score= 0.8722741433021807\n",
      "\n",
      "\n",
      "Cross_val_score= 0.8698657358541414\n",
      "\n",
      "\n",
      "roc auc score= 0.8698709327444365\n",
      "\n",
      "\n",
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.76      0.85      1726\n",
      "           1       0.81      0.98      0.89      1805\n",
      "\n",
      "    accuracy                           0.87      3531\n",
      "   macro avg       0.89      0.87      0.87      3531\n",
      "weighted avg       0.89      0.87      0.87      3531\n",
      "\n",
      "\n",
      "\n",
      "[[1316  410]\n",
      " [  41 1764]]\n",
      "\n",
      "\n",
      "************************* RandomForestClassifier ***********************\n",
      "\n",
      "\n",
      "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
      "                       criterion='gini', max_depth=None, max_features='auto',\n",
      "                       max_leaf_nodes=None, max_samples=None,\n",
      "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
      "                       min_samples_leaf=1, min_samples_split=2,\n",
      "                       min_weight_fraction_leaf=0.0, n_estimators=100,\n",
      "                       n_jobs=None, oob_score=False, random_state=55, verbose=0,\n",
      "                       warm_start=False)\n",
      "\n",
      "\n",
      "accuracy_score= 0.9985839705465873\n",
      "\n",
      "\n",
      "Cross_val_score= 0.9878190818706509\n",
      "\n",
      "\n",
      "roc auc score= 0.9985896007934699\n",
      "\n",
      "\n",
      "Classification report\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      1726\n",
      "           1       1.00      1.00      1.00      1805\n",
      "\n",
      "    accuracy                           1.00      3531\n",
      "   macro avg       1.00      1.00      1.00      3531\n",
      "weighted avg       1.00      1.00      1.00      3531\n",
      "\n",
      "\n",
      "\n",
      "[[1724    2]\n",
      " [   3 1802]]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Model=[]\n",
    "score=[]\n",
    "cvs=[]\n",
    "rocscore=[]\n",
    "for name,model in models:\n",
    "    print('*************************',name,'***********************')\n",
    "    print('\\n')\n",
    "    Model.append(name)\n",
    "    model.fit(x_train1,y_train1)\n",
    "    print(model)\n",
    "    pre1=model.predict(x_test1)\n",
    "    print('\\n')\n",
    "    AS=accuracy_score(y_test1,pre1)\n",
    "    print('accuracy_score=',AS)\n",
    "    score.append(AS*100)\n",
    "    print('\\n')\n",
    "    sc=cross_val_score(model,x_new,y_new,cv=10,scoring='accuracy').mean()\n",
    "    print('Cross_val_score=',sc)\n",
    "    cvs.append(sc*100)\n",
    "    print('\\n')\n",
    "    false_positive_rate,true_positive_rate,thresholds=roc_curve(y_test1,pre1)\n",
    "    roc_auc=auc(false_positive_rate,true_positive_rate)\n",
    "    print(\"roc auc score=\",roc_auc)\n",
    "    rocscore.append(roc_auc*100)\n",
    "    print('\\n')\n",
    "    print('Classification report\\n',classification_report(y_test1,pre1))\n",
    "    print('\\n')\n",
    "    cm=confusion_matrix(y_test1,pre1)\n",
    "    print(cm)\n",
    "    print('\\n')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy_score</th>\n",
       "      <th>Cross_val_score</th>\n",
       "      <th>Roc_auc_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>97.281223</td>\n",
       "      <td>93.756926</td>\n",
       "      <td>97.312827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC</td>\n",
       "      <td>91.617106</td>\n",
       "      <td>90.895736</td>\n",
       "      <td>91.588818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>93.712829</td>\n",
       "      <td>92.867343</td>\n",
       "      <td>93.633608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>98.923818</td>\n",
       "      <td>97.597814</td>\n",
       "      <td>98.919475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GaussianNB</td>\n",
       "      <td>87.227414</td>\n",
       "      <td>86.986574</td>\n",
       "      <td>86.987093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>99.858397</td>\n",
       "      <td>98.781908</td>\n",
       "      <td>99.858960</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Model  Accuracy_score  Cross_val_score  Roc_auc_score\n",
       "0    KNeighborsClassifier       97.281223        93.756926      97.312827\n",
       "1                     SVC       91.617106        90.895736      91.588818\n",
       "2      LogisticRegression       93.712829        92.867343      93.633608\n",
       "3  DecisionTreeClassifier       98.923818        97.597814      98.919475\n",
       "4              GaussianNB       87.227414        86.986574      86.987093\n",
       "5  RandomForestClassifier       99.858397        98.781908      99.858960"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking all classifiers cross val score and roc_auc_score\n",
    "result=pd.DataFrame({'Model': Model, 'Accuracy_score':score,'Cross_val_score':cvs,'Roc_auc_score':rocscore})\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rf.avacado.pkl']"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as per the above analysis RandomForestClassifier is the perfect model\n",
    "from sklearn.externals import joblib\n",
    "joblib.dump(rf,'rf.avacado.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
